{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "nn_model_sf = load_model('../model/single_family_nn_model.keras')\n",
    "nn_model_th = load_model('../model/townhouse_nn_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare the New Dataset\n",
    "- Ensure that your new dataset is preprocessed in the same way as the dataset you used to train the model. This includes:\n",
    "    -  Handling Missing Values: Fill or drop any missing data as needed.\n",
    "    -   Feature Scaling: Use the same scaling method (e.g., StandardScaler) that was applied to the original training data. You'll need to load the same scaler or apply the same scaling method to the new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the new dataset\n",
    "new_data = pd.read_csv('new_dataset.csv')\n",
    "\n",
    "# Convert 'Date' to datetime if present\n",
    "new_data['Date'] = pd.to_datetime(new_data['Date'], format='%Y-%m')\n",
    "\n",
    "# Remove commas and convert GDP column to numeric if needed\n",
    "new_data['All industries GDP'] = new_data['All industries GDP'].replace({',': ''}, regex=True).astype(float)\n",
    "\n",
    "# Handle missing values\n",
    "new_data.fillna(new_data.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "# Select features (excluding target variables if present)\n",
    "X_new = new_data.drop(columns=['Date', 'Single_Family_Benchmark_SA', 'Townhouse_Benchmark_SA'], errors='ignore')\n",
    "\n",
    "# Apply the same scaling as was used for the training data\n",
    "X_new_scaled = scaler.transform(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Make Predictions\n",
    "Use the loaded model to make predictions on the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Single Family Benchmark SA for the new data\n",
    "predictions_sf = nn_model_sf.predict(X_new_scaled)\n",
    "\n",
    "# Predict Townhouse Benchmark SA for the new data\n",
    "predictions_th = nn_model_th.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Interpret the Predictions\n",
    "The output **predictions_sf** and **predictions_th** will be arrays of predicted values for Single_Family_Benchmark_SA and Townhouse_Benchmark_SA, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to a DataFrame (optional)\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Predicted_Single_Family_Benchmark_SA': predictions_sf.flatten(),\n",
    "    'Predicted_Townhouse_Benchmark_SA': predictions_th.flatten()\n",
    "})\n",
    "\n",
    "# Optionally, save the predictions to a CSV file\n",
    "predictions_df.to_csv('predicted_house_prices.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Considerations:\n",
    "- **Consistency:** Ensure that the features in your new dataset match the features used to train the model. Any mismatch in columns will cause errors.\n",
    "- **Scaling:** Always apply the same scaler used during training to your new data. If the scaler was saved, load it and use it to transform the new data.\n",
    "\n",
    "By following these steps, you can effectively use your saved neural network models to make predictions on new datasets, ensuring that your preprocessing steps remain consistent with the original training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To automate the process of loading a saved model, preprocessing a new dataset, making predictions, and saving the results, you can create a Python script or function. \n",
    "\n",
    "Below is an example of how to structure this into a reusable function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create the Automation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def predict_house_prices(model_path, scaler, input_csv, output_csv):\n",
    "    # Load the saved model\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Load the new dataset\n",
    "    new_data = pd.read_csv(input_csv)\n",
    "\n",
    "    # Convert 'Date' to datetime if present\n",
    "    if 'Date' in new_data.columns:\n",
    "        new_data['Date'] = pd.to_datetime(new_data['Date'], format='%Y-%m')\n",
    "\n",
    "    # Remove commas and convert GDP column to numeric if needed\n",
    "    if 'All industries GDP' in new_data.columns:\n",
    "        new_data['All industries GDP'] = new_data['All industries GDP'].replace({',': ''}, regex=True).astype(float)\n",
    "\n",
    "    # Handle missing values\n",
    "    new_data.fillna(new_data.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "    # Select features (excluding target variables if present)\n",
    "    features_to_drop = ['Date', 'Single_Family_Benchmark_SA', 'Townhouse_Benchmark_SA']\n",
    "    X_new = new_data.drop(columns=features_to_drop, errors='ignore')\n",
    "\n",
    "    # Apply the same scaling as was used for the training data\n",
    "    X_new_scaled = scaler.transform(X_new)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_new_scaled)\n",
    "\n",
    "    # Create a DataFrame with the predictions\n",
    "    predictions_df = pd.DataFrame(predictions, columns=['Predicted_House_Prices'])\n",
    "\n",
    "    # Combine with the original data if needed\n",
    "    result_df = pd.concat([new_data, predictions_df], axis=1)\n",
    "\n",
    "    # Save the predictions to a CSV file\n",
    "    result_df.to_csv(output_csv, index=False)\n",
    "    print(f'Predictions saved to {output_csv}')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Assume you have the scaler saved as a pickle file, load it\n",
    "    import pickle\n",
    "    with open('scaler.pkl', 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    \n",
    "    # Predict Single Family prices\n",
    "    predict_house_prices('single_family_nn_model.keras', scaler, 'new_dataset.csv', 'predicted_single_family_prices.csv')\n",
    "\n",
    "    # Predict Townhouse prices\n",
    "    predict_house_prices('townhouse_nn_model.keras', scaler, 'new_dataset.csv', 'predicted_townhouse_prices.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Save and Load the Scaler\n",
    "When you trained your model, you used a StandardScaler to normalize the data. \n",
    "\n",
    "You need to save this scaler and load it when predicting new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the Scaler:\n",
    "import pickle\n",
    "\n",
    "# Assuming you have already fitted the scaler\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Scaler:\n",
    "\n",
    "- The **predict_house_prices** function above assumes the scaler is loaded before being passed to the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Running the Script\n",
    "Save the script to a .py file (e.g., predict_house_prices.py). You can then run the script from the command line:\n",
    "\n",
    "![image](https://github.com/hitechparadigm/team_project_2/blob/team-project-2/img/automate_script.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
